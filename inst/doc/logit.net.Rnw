\documentclass{article}

\title{
  logit.net: Network Logistic Regression for Dichotomous Proximity Matrix 
  Dependent Variables
}

\author{Matt Owen, Olivia Lau, Kosuke Imai, and Gary King}

\SweaveOpts{results=hide, prefix.string=vigpics/logitnet}

\usepackage{bibentry}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{url}
\usepackage{Zelig}
\usepackage{Sweave}

%\VignetteIndexEntry{Network Logistic Regression for Dichotomous Proximity Matrix Dependent Variables}
%\VignetteDepends{Zelig, stats}
%\VignetteKeyWords{model,least squares,continuous, regression}
%\VignettePackage{Zelig}

\begin{document}
\nobibliography*

<<loadLibrary, echo=F,results=hide>>=
library(ZeligNetwork)
@ 

\section{{\tt logit.net}: Network Logistic Regression for Dichotomous Proximity Matrix Dependent Variables}

Use network logistic regression analysis for a dependent variable that is a binary valued proximity matrix (a.k.a. sociomatricies, adjacency matrices, or matrix representations of directed graphs). 

\subsubsection{Syntax}
\begin{verbatim}
> z.out <- zelig(y ~ x1 + x2, model = "logit.net", data = mydata) 
> x.out <- setx(z.out)
> s.out <- sim(z.out, x = x.out)
\end{verbatim}



\subsubsection{Examples}
\begin{enumerate}
\item Basic Example

Load the sample data (see {\tt ?friendship} for details on the structure of the network dataframe):

<<echo=TRUE, results=hide, fig=FALSE>>=
data(friendship)



@
Estimate model:

<<echo=TRUE, results=hide, fig=FALSE>>=
z.out <- zelig(friends ~ advice + prestige + perpower, model = "logit.net", data = friendship)
summary(z.out)

@
Setting values for the explanatory variables to their default values:

<<echo=TRUE, results=hide, fig=FALSE>>=
x.out <- setx(z.out)

@
Simulating quantities of interest from the posterior distribution.
<<echo=TRUE, results=hide, fig=FALSE>>=
s.out <- sim(z.out, x = x.out) 
summary(s.out) 
plot(s.out) 

@

\begin{figure}[here]
\centering
<<fig=TRUE, echo=false,width=12, height=6>>=
plot(s.out)
@
\label{fig:plotgam}
\end{figure}


\item Simulating First Differences

Estimating the risk difference (and risk ratio) between low personal power (25th percentile) and high personal power (75th percentile) while all the other variables are held at their default values. 

<<echo=TRUE, results=hide, fig=FALSE>>=
x.high <- setx(z.out, perpower = quantile(friendship$perpower, prob = 0.75))    
x.low  <- setx(z.out, perpower = quantile(friendship$perpower, prob = 0.25))

s.out2 <- sim(z.out, x = x.high, x1 = x.low)   
summary(s.out2)   
plot(s.out2)   

@

\begin{figure}[here]
\centering
<<fig=TRUE,echo=false, width=12, height=6>>=
plot(s.out)
@
\label{fig:plotgam}
\end{figure}



\end{enumerate}



\subsubsection{Model}
The {\tt logit.net} model performs a logistic regression of the proximity matrix $\mathbf{Y}$, a $m \times m$ matrix representing network ties, on a set of proximity matrices $\mathbf{X}$. This network regression model is directly analogous to standard logistic regression element-wise on the appropriately vectorized matrices. Proximity matrices are vectorized by creating $Y$, a $m^2 \times 1$ vector to represent the proximity matrix. The vectorization which produces the $Y$ vector from the $\mathbf{Y}$ matrix is performed by simple row-concatenation of $\mathbf{Y}$. For example, if $\mathbf{Y}$ is a $15 \times 15$ matrix, the $\mathbf{Y}_{1,1}$ element is the first element of $Y$, and the $\mathbf{Y}_{2,1}$ element is the second element of $Y$ and so on. Once the input matrices are vectorized, standard logistic regression is performed. 

Let $Y_{i}$ be the binary dependent variable, produced by vectorizing a binary proximity matrix, for observation $i$ which takes the value of either 0 or 1.
\begin{itemize}
\item The \emph{stochastic component} is given by 
\begin{eqnarray*}
Y_{i} & \sim \text{Bernoulli} (y_{i} | \pi_{i})\\
& = \pi_{i}^{y_{i}} (1 - \pi_{i})^{1 - y_{i}}
\end{eqnarray*}
where $\pi_{i} = \text{Pr}(Y_{i} = 1)$.
\item The \emph{systematic component} is given by:
\begin{equation*}
\pi_{i} = \frac{1}{1 + \exp(-x_{i}\beta)}.
\end{equation*}
where $x_{i}$ is the vector of $k$ covariates for observation $i$ and $\beta$ is the vector of coefficients.
\end{itemize}


\subsubsection{Quantities of Interest}
The quantities of interest for the network logistic regression are the same as those for the standard logistic regression. 
\begin{itemize}
\item The expected values ({\tt qi\$ev}) for the {\tt logit.net} model are simulations of the predicted probability of a success:  
\begin{equation*}
E(Y) = \pi_{i} = \frac{1}{1 + \exp(-x_{i}\beta)},
\end{equation*}
given draws of $\beta$ from its sampling distribution.

\item The predicted values ({\tt qi\$pr}) are draws from the Binomial distribution with mean equal to the simulated expected value $\pi_{i}$.

\item The first difference ({\tt qi\$fd}) for the network logit model is defined as 
\begin{equation*}
FD = \text{Pr}(Y = 1 | x_{1}) - \text{Pr}(Y = 1| x)
\end{equation*}
\end{itemize}


\subsubsection{Output Values}

The output of each Zelig command contains useful information which you may view. For example, you run \verb{ z.out <- zelig(y ~ x, model = "logit.net", data){, then you may examine the available information in {\tt z.out} by using {\tt names(z.out)}, see the coefficients by using {\tt z.out\$coefficients}, and a default summary of information through {\tt summary(z.out)}. Other elements available through the {\tt \$} operator are listed below. 
\begin{itemize}
\item From the {\tt zelig()} output stored in {\tt  z.out}, you may extract:
\begin{itemize}
\item {\tt coefficients}: parameter estimates for the explanatory variables.
\item {\tt fitted.values}: the vector of fitted values for the explanatory variables.
\item {\tt residuals}: the working residuals in the final iteration of the IWLS fit. 
\item {\tt linear.predictors}: the vector of $x_{i}\beta$.
\item {\tt aic}: Akaike\'s Information Criterion (minus twice the maximized log-likelihood plus twice the number of coefficients).
\item {\tt bic}: the Bayesian Information Criterion (minus twice the maximized log-likelihood plus the number of coefficients times log $n$).
\item {\tt df.residual}: the residual degrees of freedom.
\item {\tt df.null}: the residual degrees of freedom for the null model. 
\item {\tt zelig.data}: the input data frame if {\tt save.data = TRUE} 

\end{itemize}
\item From {\tt summary(z.out)}(as well as from {\tt zelig()}), you may extract:
\begin{itemize}
\item {\tt mod.coefficients}: the parameter estimates with their associated standard errors, $p$-values, and $t$ statistics. 
\item {\tt cov.scaled}: a $k \times k$ matrix of scaled covariances.
\item {\tt cov.unscaled}: a $k \times k$ matrix of unscaled covariances. 
\end{itemize}
\item From the {\tt sim()} output stored in {\tt s.out}, you may extract:
\begin{itemize}
\item {\tt qi\$ev}: the simulated expected probabilities for the specified values of {\tt x}.
\item {\tt qi\$pr}: the simulated predicted values for the specified values of {\tt x}.
\item {\tt qi\$fd}: the simulated first differences in the expected probabilities simulated from {\tt x} and {\tt x1}.
\end{itemize}
\end{itemize}

\subsection*{How to Cite Network Log-Log Regeression} 
\bibentry{ImaLauKin-logit.net11}

\subsection*{How to Cite the Zelig Software Package}
\CiteZelig

\subsection* {See also}
The network logistic regression is part of the {\tt netglm} package by Skyler J. Cranmer and is built using some of the functionality of the  {\tt sna} package by Carter T. Butts \citep{ButCar01}.In addition, advanced users may wish to refer to {\tt help(netgamma)}. Sample data are fictional. 
 
\bibliographystyle{plain}
\bibliography{gk,gkpubs,ZeligNetwork}

\end{document}
